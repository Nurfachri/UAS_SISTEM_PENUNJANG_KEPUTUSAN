{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcbe00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53be873c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "word_stemmer = PorterStemmer()\n",
    "word_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28fe66a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "Lanc_stemmer = LancasterStemmer()\n",
    "Lanc_stemmer.stem('eats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceaa1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133a723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fae3339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4da633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer\n",
      "eat\n",
      "play\n",
      "play\n",
      "play\n",
      "Lancaster Stemmer\n",
      "eat\n",
      "play\n",
      "play\n",
      "play\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "print(\"Porter Stemmer\")\n",
    "print(porter.stem(\"eats\"))\n",
    "print(porter.stem(\"play\"))\n",
    "print(porter.stem(\"playing\"))\n",
    "print(porter.stem(\"played\"))\n",
    "print(\"Lancaster Stemmer\")\n",
    "print(porter.stem(\"eats\"))\n",
    "print(porter.stem(\"play\"))\n",
    "print(porter.stem(\"playing\"))\n",
    "print(porter.stem(\"played\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2675069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Porter Stemmer      Lancester Stemmer   \n",
      "enemy               enemi               enemy               \n",
      "boyfriend           boyfriend           boyfriend           \n",
      "friends             friend              friend              \n",
      "friendship          friendship          friend              \n",
      "stabilise           stabilis            stabl               \n",
      "destabilize         destabil            dest                \n",
      "miseunderstanding   miseunderstand      miseunderstand      \n",
      "reading             read                read                \n",
      "playing             play                play                \n",
      "sunlight            sunlight            sunlight            \n",
      "football            footbal             footbal             \n"
     ]
    }
   ],
   "source": [
    "word_list = [\"enemy\",\"boyfriend\",\"friends\",\"friendship\",\"stabilise\",\"destabilize\",\"miseunderstanding\",\"reading\",\"playing\",\"sunlight\",\"football\"]\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"Lancester Stemmer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,porter.stem(word),lancaster.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf726a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google is the place to find anything we want.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Google is the place to find anything we want.\"\n",
    "porter.stem(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "206a8870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "googl is the place to find anyth we want . \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "x=stemSentence(sentence)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c54d3fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The birth of e-commerce in Indonesia stems from the presence of IndoNet. At that time, IndoNet was the Internet Service Provider (ISP) in Indonesia. The emergence of IndoNet became the forerunner to the use of technology in all fields. The online business is no exception.\\n\\nThen, in 1996, Dyviacom Intrabumi or D-Net appeared which is considered a pioneer of online buying and selling. The presence of this transaction media is of course good news for not only business owners but consumers. By using the internet, the transaction process will be much easier.\\n\\nHowever, at first, the use of the internet was only limited to displaying products. For payment transactions, the seller and the consumer still have to meet. The term was later called cash on delivery (COD).\\n\\nAs technology advances, there are also online stores. Then, this is the starting point for the emergence of e-commerce in Indonesia.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=open(\"DeepLearning.txt\")\n",
    "file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a2fd4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The birth of e-commerce in Indonesia stems from the presence of IndoNet. At that time, IndoNet was the Internet Service Provider (ISP) in Indonesia. The emergence of IndoNet became the forerunner to the use of technology in all fields. The online business is no exception.\\n',\n",
       " '\\n',\n",
       " 'Then, in 1996, Dyviacom Intrabumi or D-Net appeared which is considered a pioneer of online buying and selling. The presence of this transaction media is of course good news for not only business owners but consumers. By using the internet, the transaction process will be much easier.\\n',\n",
       " '\\n',\n",
       " 'However, at first, the use of the internet was only limited to displaying products. For payment transactions, the seller and the consumer still have to meet. The term was later called cash on delivery (COD).\\n',\n",
       " '\\n',\n",
       " 'As technology advances, there are also online stores. Then, this is the starting point for the emergence of e-commerce in Indonesia.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=open(\"DeepLearning.txt\")\n",
    "my_lines_list=file.readlines()\n",
    "my_lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bd2364d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The birth of e-commerce in Indonesia stems from the presence of IndoNet. At that time, IndoNet was the Internet Service Provider (ISP) in Indonesia. The emergence of IndoNet became the forerunner to the use of technology in all fields. The online business is no exception.\n",
      "\n",
      "Stemmed sentence\n",
      "the birth of e-commerc in indonesia stem from the presenc of indonet . at that time , indonet wa the internet servic provid ( isp ) in indonesia . the emerg of indonet becam the forerunn to the use of technolog in all field . the onlin busi is no except . \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def StemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "    \n",
    "print(my_lines_list[0])\n",
    "print(\"Stemmed sentence\")\n",
    "x=StemSentence(my_lines_list[0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb0af7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "is                  is                  \n",
      "playing             playing             \n",
      "football            football            \n",
      "with                with                \n",
      "his                 his                 \n",
      "friends             friend              \n",
      "He                  He                  \n",
      "goes                go                  \n",
      "to                  to                  \n",
      "school              school              \n",
      "with                with                \n",
      "his                 his                 \n",
      "friends             friend              \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence_1 = \"He is playing football with his friends. He goes to school with his friends.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence_1)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9e9ca9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He                  He                  \n",
      "is                  be                  \n",
      "playing             play                \n",
      "football            football            \n",
      "with                with                \n",
      "his                 his                 \n",
      "friends             friends             \n",
      "He                  He                  \n",
      "goes                go                  \n",
      "to                  to                  \n",
      "school              school              \n",
      "with                with                \n",
      "his                 his                 \n",
      "friends             friends             \n"
     ]
    }
   ],
   "source": [
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec84901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
